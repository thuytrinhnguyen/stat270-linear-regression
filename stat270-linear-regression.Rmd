---
title: "STAT270 Assignment"
author: "Thuy Trinh Nguyen"
date: "19/05/2019"
output:
  word_document: default
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1
First, read in the file.

```{r read file}
seaice = read.csv("seaice.csv", header = TRUE)
```

Then , create a subset of data from 1979 - 2002.

``` {r create subset data}
seaice_97_2k2 <- subset(seaice, seaice$Year <= 2002)
```

### a. [3 marks] State the statistical model for a simple linear regression of Extent explained by Year. Carefully define all the necessary variables and parameters in your answer.
The statistical model: 
$$ Extent_i = \beta_0 + \beta_1Year_i + \varepsilon_i \, \, \, \, \, ;\, \, \, \, \,\varepsilon \sim \mathcal{N(0,\sigma^{2})}$$

$Extent_i:$ The average September Sea Ice Extent (in 1,000,000 $km^{2}$) (the response variable)

$Year_i:$ The year (the predictor variable)

$\beta_0:$ The intercept

$\beta_1:$ The slope (how much does the increase in year affect the extent of sea ice)

$\varepsilon_i:$ The unexplained variations (which are independently and identically - normally distributed) $\varepsilon \sim \mathcal{N(0,\sigma^{2})}$

### b. [3 marks] A simple linear regression seems appropriate for the 1979-2002 data. Justify the use of a simple linear regression model.
To justify the model, we will look at the following plots.

```{r 1979 - 2002 plot}
seaice_97_2k2.lm = lm(Extent ~ Year, data = seaice_97_2k2)

par(mfrow = c(1,2))
plot(seaice_97_2k2.lm, which = 1:2)
```

1. Justify the normality assumption based on the Normal QQ Plot

From the plot, we can see that although the residuals do not form a perfect straight line, the shape does not have a significant curve. The normality assumption is checked.

2. Justify the constant variance assumption based on the Residuals VS Fitted Plot

As the observations spread fairly equal with no obvious pattern, we can conclude that the constant variance assumption is fulfilled.

Hence, from the two plots above, applying a simple linear regression model is appropriate.


### c. [2 marks] Fit a simple linear regression to the 1979-2002 data. Explain why there is a linear relationship.
``` {r model fitting}
summary(seaice_97_2k2.lm)
```
As the P Value is significant (p-value = 0.00176 < $\alpha = 0.05$), the fitted model is:
$$ \widehat{Extent_i} = 98.1518 - 0.04587\,Year_i$$

From the summary, we can see the p-value is highly statistically significant and that the slope is equal to $(- 0.04587)$, which is not equal to zero. This means that, as one year goes by, the average of September Sea ice extent decreases by 45,870 $km^{2}$ on average, so there is a linear relationship.

### d. [2 marks] Is this a strong linear relationship? Explain your answer in the context of this data.
```{r correlation}
cor(seaice_97_2k2$Year, seaice_97_2k2$Extent)
```
It is reasonable to assume that the linear relationship is not very strong. Although the correlation is fairly high ($r = -0.6043868$), the R-squared ($ =36.54\%$) from the linear regression summary suggests that the goodness of fit is low compared to the ideal rate of 70%.

In this context, it is reasonable to believe that there are more factors that affect the area of sea ice other than time. There could be human activities, climate change, etc. that make sea ice melts.

### e. [2 marks] Predict the extent of the sea ice (in km2) for the year 2000.
The sea ice for the year 2000 $= 98.1518 - 0.0458 \times 2000 = 6.5518 \,(km^{2})$ 

The sea ice for the year 2000 is $6.5518 \,km^{2}$

### f. [2 marks] Compute a 95% prediction band for the Extent of Sea Ice (in km2) in the year 2000.
```{r prediction band}
predband = predict.lm(seaice_97_2k2.lm, newdata = data.frame(Year = c(2000)), interval = 'prediction')
predband
```

The 95% prediction band for the Extent of Sea Ice (in km2) in the year 2000 is (5.461929 , 7.380798).

### g. [2 marks] Compute a 95% confidence band for the Extent of Sea Ice (in km2) in the year 2000.
```{r confidence band}
confband = predict.lm(seaice_97_2k2.lm, newdata = data.frame(Year = c(2000)), interval = 'confidence')
confband
```

The 95% confidence band for the Extent of Sea Ice (in km2) in the year 2000 is (6.107146 , 6.735582).

### h. [2 marks] Explain clearly what the prediction band represents and what the confidence band represents.
The confidence band represents the interval that we are (for example: 95%) confident that the true mean (the average) lies within.

The prediction band represents the interval that we are (for example: 95%) confident that the response value of an individual at a particular predictor value lies within.


### i. [2 marks] Justify why a simple linear regression is inappropriate for the 1979-2012 data.
To justify the model, we will look at the following plots.

```{r plot data 1979 - 2012}
seaice.lm = lm(Extent ~ Year, data = seaice)

par(mfrow = c(1,2))
plot(seaice.lm, which = 1:2)
```

1. Justify the normality assumption: 

From the Normal QQ plot, we can see that the residuals form a fairly straight line suggesting that the errors are normally distributed.

2. Justify the constant variance assumption:

From the Residuals VS Fitted plot, there is a clear curvative pattern (concave down). Therefore, it is reasonable to conclude that the constant variance assumption is unsatisfied.

Hence, a simple linear regression is not appropriate to apply to the 1979 - 2012 data.


### j. [3 marks] Fit a second order polynomial regression model to the data and validate the model.
``` {r 2nd polynomial model fitting}
seaice_2nd_poly.lm = lm(Extent ~ Year + I(Year^2), data = seaice) 

par(mfrow = c(1,2))
plot(seaice_2nd_poly.lm, which = 1:2)
```

From updated the Normal QQ plot, the residuals form a fairly straight line. Hence, the normality assumption is fulfiiled.

From the Residuals VS Fitted plot, there is not an obvious pattern. 

Overall, it is suggested that the quadratic fit is sufficient.

### k. [1 mark] Plot the fitted polynomial to your data
``` {r plot the line of fitted}
plot(seaice$Extent ~ seaice$Year)
extent_hat = predict.lm(seaice_2nd_poly.lm, newdata = data.frame(Year = seaice$Year))

lines(seaice$Year,extent_hat, col = "red")
```


### l. [2 marks] Using the second order model you fitted, predict the extent of the sea ice (in km2) for the year 2000.
``` {r 2nd polynomial regression summary}
summary(seaice_2nd_poly.lm)
```
The fitted model is: $\widehat{Extent_i} = - 15400 + 15.53Year_i - 0.003912{Year_i}^{2}$

The sea ice for the year 2000 $= - 15400 + 15.53 \times 2000 - 0.003912 \times 2000^{2} = 12\,(km^{2})$ 

The sea ice for the year 2000 is $12 \,km^{2}$

### m. [2 marks] Compare your answers in part e) and part l). Which prediction value do you recommend and why?
The answers in question e) and l) are  $6.5518 \,km^{2}$ and $12 \,km^{2}$ respectively.

The answer in question l) should be recommended as the quadratic is a better fitted model in this situation.


# Question 2
First, read in the file.
``` {r read in the wine dataset}
wine = read.csv("pwine.csv", header = TRUE)
```

### a. [4 marks] State the statistical model for a multiple regression with Quality as the response using all other variables as predictors, defining any parameters as necessary.
The statistical model: 
$$ Quality_i = \beta_0 + \beta_1Alcohol_i + \beta_2Density_i + \beta_3pH_i + \varepsilon_i \, \, \, \, \, ;\, \, \, \, \,\varepsilon \sim \mathcal{N(0,\sigma^{2})}$$

$Quality_i:$ Aggregated score across the taste testers (the response variable)

$Alcohol_i:$ Level of alcohol in percent (the predictor variable)

$Density_i:$ Density or specific gravity of the wine (the predictor variable)

$pH_i:$ Acidity level of the wine (the predictor variable)

$\beta_0:$ The intercept

$\beta_1, \beta_2, \beta_3:$ The partial regression coefficients (how much do the increase Alcohol, Density and pH levels affect the Quality of the wine respectively)

$\varepsilon_i:$ The unexplained variations (which are independently and identically - normally distributed) $\varepsilon \sim \mathcal{N(0,\sigma^{2})}$

### b. [2 marks] Fit this multiple regression model and write down the fitted model.
``` {r the fitted model}
wine.lm = lm(Quality ~ Alcohol + Density + pH, data = wine)
summary(wine.lm)
```

The fitted model is: $\widehat{Quality_i} =  - 46.18943 + 0.3819\,Alcohol_i + 51.33496\,Density_i - 0.84169\,pH_i$

### c. [4 marks] What are the assumptions required for a multiple regression analysis? If possible, validate those assumptions for the multiple regression model you fitted in part b.
Similar to the simple linear regression model, a multiple regression analysis requires the satisfaction of these assumptions: normality, constant variance and the independence of observations.

``` {r check assumptions for multiple linear regression - plot}
par(mfrow = c(1,2))
plot(wine.lm, which = 1:2)
```

It is indicated from the Normal QQ plot that the residuals form a fairly straight line (except for some outliers) and that they are close to linear. Hence, the normality assumption is fulfilled.

The Residuals VS Fitted plot shows a heavier concentration on the left half of the plot due to the existence of some outliers. If we do not consider these outliers, the plot will appear to have an equal spread and there will be no obvious pattern.


### d. [6 marks] Conduct an F-test for the overall regression i.e. is there any relationship between the response and the predictors. Write your answer as a formal hypothesis test and include the ANOVA table (one combined regression SS source is sufficient.)

#### 1. Hypothesis

$$H_0: \beta_1 = \beta_2 = \beta_3 = 0 \,\,\,\,;\,\,\, H_1: \beta_i\, \,{\neq 0}\, (at\, least \,one \,i)$$

#### 2. Assumptions
Conducting the analysis, it is assumed that:

- The observations are collected independently.

- The errors of the model form a normal distribution $\varepsilon \sim \mathcal{N}(0,\sigma^{2})$

- The variances of residuals are equal. 

#### 3. Test Statistics
``` {r f-test}
wine.lm = lm(Quality ~ Alcohol + Density + pH, data = wine)

summary(wine.lm)
anova(wine.lm)
```

Full Regression SS $= 35.813 + 4.382 + 4.036 = 44.231$

Regression MS = $\frac{Regression SS}{k}= \frac{44.231}{3} = 14.74367$

$$F (obs) = \frac{Regression MS}{Residual MS} = \frac{14.7436}{0.562} = 26.23416$$

#### 4. Analysis
$P(F_3,_{282}) = 5.47\times 10^{-15} < 0.05$

The result is significant as the P Value is smaller than $alpha$. Hence, we reject the null hypothesis ($H_0$) and say that there is a significant linear relationship between the response variable (Quality) and at least one of the three predictor variables (Alcohol, Density, pH).

#### 5. Conslusion
1. Statistical conclusion

The P values are smaller than 0.05, we reject the null hypothesis ($H_0$) and say that there is a linear relationship between the response variable (Quality) and at least one of the three predictors (Alcohol, Density, pH).

2. Contextual conclusion

The Quality of the wine depends on at least one of the factors: the level of Alcohol, density or the pH level of the wine. 

One percentage increases in the level of Alcohol will results in an increase of 0.38 score in Quality.

One level increases in the acidity of the wine will results in a decrease of 0.84 score in Quality.

Hence, to improve the Quality of the wine, it is reasonable to increase the Acohol level and decrease the acidity.


### e. [3 marks] From the analysis in part b. determine the 95% CI for the Alcohol slope parameter and comment on its meaning in this context.

``` {r confidence interval for Alcohol slope parameter at 95%}
confint(wine.lm, c("Alcohol"), level = 0.95)
```

The 95% confidence interval for the Alcohol slope parameter is $(0.2889363 , 0.4748607)$.

In this context, it means that the true average impact of an increase in 1 percentage of the Acohol level on Quality of wine lies between 0.2889363 and 0.4748607 score.

### f. [2 marks] Using the model selection procedures used in this course, find the best multiple regression model that explains the data giving reasons for your choice(s).

First, we will look at the orginal model with all three predictors.

P-value of Alcohol predictor $= 1.83 \times 10^{-14}$ and p-value of pH predictor $= 0.00782$, both are smaller than 0.05 and are significant. While Density is the only predictor whose value is not significant at $\alpha = 0.05$.

Therefore, it is reasonable to start by removing the predictor Density.

``` {r model with 2 predictors: Alcohol and pH}
wine_alcohol_pH.lm = lm(Quality ~ Alcohol + pH, data = wine)
summary(wine_alcohol_pH.lm)
anova(wine_alcohol_pH.lm)
```

From the results above, it can be seen that both predictors have significant p-values. 

The following table demonstrate the impact of some of the predictor combinations as a summary for the tested multiple linear regression and ANOVA analysis for reference.

|  Model with Predictor  | Insignificant p-value | R-squared | Adjusted R-squared | Total SQ |
|:----------------------:|:---------------------:|:---------:|:------------------:|:--------:|
| Alcohol - Density - pH |        Density        |   21.81%  |       20.98%       |  44.231  |
| Alcohol - pH           |          None         |   21.02%  |       20.47%       |  42.639  |
| Alcohol - Density      |          None         |   19.82%  |       18.25%       |  40.195  |
| Density - pH           |          None         |   3.678%  |       2.997%       |   7.459  |

The following table demonstrate the impact of each predictor as a summary for the tested multiple linear regression and ANOVA analysis for reference.

| Predictor | Contribution to  R-squared | Contribution to  Adjusted R-squared | Sum of Square |
|:---------:|:--------------------------:|:-----------------------------------:|:-------------:|
|  Alcohol  |           18.132%          |               17.983%               |     36.772    |
|  Density  |            0.79%           |                0.51%                |     1.592     |
|     pH    |            1.99%           |                1.73%                |     6.036     |

From the analysis above, it is suggested that the predictors Alcohol and pH should remain considered in the model as the multilinear regression model with the two stated predictors have significant p-values and explain the response variation the second best (considering R-squared and Adjuste R-squared). 

Note: The highest R-squared and Adjusted R-squared is the original model with three predictors, but there is an insignificant p-value and Density only contribute a marignal percentage in explaining the model. Hence, removing Density is adequate.

### g. [4 marks] State the final fitted regression model and comment on its interpretation.

The final fitted regression model: $\widehat{Quality_i} =  6.0141 + 0.3409\,Alcohol_i - 1.0260\,pH_i$

Interpretation: 

1% increase in level of alcohol in the wine results in an increase of 0.3409 score in Quality testing and an increase in 1 level of acidity in the wine will decreases 1.0206 Quality score.  